# -*- coding: utf-8 -*-
"""LinkedIn Insights.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mu2GPaFAUn7Ffz2xB8O3x1UKpBxhzggK
"""

# Loop through each row in the DataFrame and geocode the location names using Google Maps Geocoding API
for index, row in df.iterrows():
    location_name = row['location']
    # Replace 'your_api_key' with your actual Google Maps Geocoding API key
    api_key = 'your_api_key'
    url = f'https://maps.googleapis.com/maps/api/geocode/json?address={location_name}&key={api_key}'
    response = requests.get(url)
    json_response = response.json()
    if json_response['status'] == 'OK':
        lat = json_response['results'][0]['geometry']['location']['lat']
        lng = json_response['results'][0]['geometry']['location']['lng']
        df.at[index, 'latitude'] = lat
        df.at[index, 'longitude'] = lng
    else:
        print(f'Geocoding failed for location: {location_name}')

# Perform geospatial analysis on the DataFrame using the geocoded latitude and longitude data
# You can now use the 'latitude' and 'longitude' columns in your DataFrame for mapping and spatial analysis
# For example, you can use libraries like geopandas or folium to create geospatial visualizations

import pandas as pd
import requests

# Load the Excel file into a pandas DataFrame
# Replace 'your_file.xlsx' with the actual filename or path to your Excel file
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

import matplotlib.pyplot as plt

# Select 5 random job titles and seniority levels from your dataset
job_titles = df['job_title'].sample(5)
seniority_levels = df['seniority_level'].sample(5)

# Create a bar chart for job titles
plt.figure(figsize=(10, 6))
plt.bar(job_titles, seniority_levels)
plt.xlabel('Job Title')
plt.ylabel('Seniority Level')
plt.title('Job Titles and Seniority Levels')
plt.xticks(rotation=45)
plt.show()

import matplotlib.pyplot as plt

# Select a sample of 15 job titles and get all available seniority levels
job_titles = df['job_title'].sample(15)
seniority_levels = df['seniority_level'].unique()

# Create a dictionary to store the count of each seniority level for the sample job titles
seniority_count = {level: 0 for level in seniority_levels}

# Loop through each row in the DataFrame and update the count for each seniority level
for index, row in df.iterrows():
    if row['job_title'] in job_titles:
        seniority_count[row['seniority_level']] += 1

# Convert the count dictionary to lists for plotting
seniority_levels = list(seniority_count.keys())
seniority_counts = list(seniority_count.values())

# Create a bar chart for job titles and seniority levels
plt.figure(figsize=(10, 6))
plt.bar(seniority_levels, seniority_counts)
plt.xlabel('Seniority Level')
plt.ylabel('Count')
plt.title('Seniority Levels for Sample Job Titles')
plt.show()

import matplotlib.pyplot as plt

# Select a sample of job titles and get all available seniority levels
job_titles = df['job_title'].sample(5)
seniority_levels = df['seniority_level'].unique()

# Create a dictionary to store the count of each seniority level for the sample job titles
seniority_count = {level: 0 for level in seniority_levels}

# Loop through each row in the DataFrame and update the count for each seniority level
for index, row in df.iterrows():
    if row['job_title'] in job_titles:
        seniority_count[row['seniority_level']] += 1

# Convert the count dictionary to lists for plotting
seniority_levels = list(seniority_count.keys())
seniority_counts = list(seniority_count.values())

# Create a bar chart for job titles and seniority levels
plt.figure(figsize=(10, 6))
plt.bar(seniority_levels, seniority_counts)
plt.xlabel('Seniority Level')
plt.ylabel('Count')
plt.title('Seniority Levels for Sample Job Titles')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Count the number of job titles by seniority level
title_seniority_counts = df.groupby(['job_title', 'seniority_level']).size().reset_index(name='counts')

# Pivot the data to create a matrix of job titles by seniority level
title_seniority_matrix = title_seniority_counts.pivot(index='job_title', columns='seniority_level', values='counts')

# Sort the matrix by the total count of each job title
title_seniority_matrix['total'] = title_seniority_matrix.sum(axis=1)
title_seniority_matrix = title_seniority_matrix.sort_values('total', ascending=False).drop('total', axis=1)

# Plot the bar chart
title_seniority_matrix.plot(kind='bar', stacked=True, figsize=(10,6))
plt.title('Distribution of Job Titles by Seniority Level')
plt.xlabel('Job Titles')
plt.ylabel('Counts')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Count the number of job titles by seniority level
title_seniority_counts = df.groupby(['job_title', 'seniority_level']).size().reset_index(name='counts')

# Pivot the data to create a matrix of job titles by seniority level
title_seniority_matrix = title_seniority_counts.pivot(index='job_title', columns='seniority_level', values='counts')

# Sort the matrix by the total count of each job title
title_seniority_matrix['total'] = title_seniority_matrix.sum(axis=1)
title_seniority_matrix = title_seniority_matrix.sort_values('total', ascending=False).drop('total', axis=1)

# Select the top 20 job titles by total count
top_20_titles = title_seniority_matrix.index[:20]
top_20_matrix = title_seniority_matrix.loc[top_20_titles]

# Plot the bar chart
top_20_matrix.plot(kind='bar', stacked=True, figsize=(12,6))
plt.title('Distribution of Top 20 Job Titles by Seniority Level')
plt.xlabel('Job Titles')
plt.ylabel('Counts')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Count the number of job titles by seniority level
title_seniority_counts = df.groupby(['job_title', 'seniority_level']).size().reset_index(name='counts')

# Pivot the data to create a matrix of job titles by seniority level
title_seniority_matrix = title_seniority_counts.pivot(index='job_title', columns='seniority_level', values='counts')

# Sort the matrix by the total count of each job title
title_seniority_matrix['total'] = title_seniority_matrix.sum(axis=1)
title_seniority_matrix = title_seniority_matrix.sort_values('total', ascending=False).drop('total', axis=1)

# Select the top 20 job titles by total count
top_20_titles = title_seniority_matrix.index[:100]
top_20_matrix = title_seniority_matrix.loc[top_20_titles]

# Plot the bar chart
top_20_matrix.plot(kind='bar', stacked=True, figsize=(12,6))
plt.title('Distribution of Top 100 Job Titles by Seniority Level')
plt.xlabel('Job Titles')
plt.ylabel('Counts')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Get the top 10 companies by job count
top_companies = df['company_name'].value_counts().head(10).index

# Subset the data to only include the top companies
df = df[df['company_name'].isin(top_companies)]

# Group the data by company name and job title
company_title_counts = df.groupby(['company_name', 'job_title']).size().reset_index(name='counts')

# Pivot the data to create a matrix of job titles by company name
company_title_matrix = company_title_counts.pivot(index='job_title', columns='company_name', values='counts')

# Sort the matrix by the total count of each job title
company_title_matrix['total'] = company_title_matrix.sum(axis=1)
company_title_matrix = company_title_matrix.sort_values('total', ascending=False).drop('total', axis=1)

# Plot the bar chart
company_title_matrix.head(10).plot(kind='bar', figsize=(12,6))
plt.title('Job Title Distribution for Top 10 Companies')
plt.xlabel('Job Titles')
plt.ylabel('Counts')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Get the top 20 companies by job count
top_companies = df['company_name'].value_counts().head(20).index

# Subset the data to only include the top companies
df = df[df['company_name'].isin(top_companies)]

# Group the data by company name and job title
company_title_counts = df.groupby(['company_name', 'job_title']).size().reset_index(name='counts')

# Pivot the data to create a matrix of job titles by company name
company_title_matrix = company_title_counts.pivot(index='job_title', columns='company_name', values='counts')

# Sort the matrix by the total count of each job title
company_title_matrix['total'] = company_title_matrix.sum(axis=1)
company_title_matrix = company_title_matrix.sort_values('total', ascending=False).drop('total', axis=1)

# Plot the bar chart
company_title_matrix.head(10).plot(kind='bar', figsize=(12,6))
plt.title('Job Title Distribution for Top 20 Companies')
plt.xlabel('Job Titles')
plt.ylabel('Counts')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Get the top 20 companies by job count
top_companies = df['company_name'].value_counts().head(30).index

# Subset the data to only include the top companies
df = df[df['company_name'].isin(top_companies)]

# Group the data by company name and job title
company_title_counts = df.groupby(['company_name', 'job_title']).size().reset_index(name='counts')

# Pivot the data to create a matrix of job titles by company name
company_title_matrix = company_title_counts.pivot(index='company_name', columns='job_title', values='counts')

# Sort the matrix by the total count of each company
company_title_matrix['total'] = company_title_matrix.sum(axis=1)
company_title_matrix = company_title_matrix.sort_values('total', ascending=False).drop('total', axis=1)

# Plot the bar chart
company_title_matrix.plot(kind='bar', stacked=True, figsize=(12,6))
plt.title('Job Title Distribution for Top 30 Companies')
plt.xlabel('Companies')
plt.ylabel('Counts')
plt.legend(title='Job Titles', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Get the top 20 companies by job count
top_companies = df['company_name'].value_counts().head(20).index

# Subset the data to only include the top companies
df = df[df['company_name'].isin(top_companies)]

# Group the data by company name and job title
company_title_counts = df.groupby(['company_name', 'job_title']).size().reset_index(name='counts')

# Pivot the data to create a matrix of job titles by company name
company_title_matrix = company_title_counts.pivot(index='job_title', columns='company_name', values='counts')

# Sort the matrix by the total count of each company
company_title_matrix['total'] = company_title_matrix.sum(axis=1)
company_title_matrix = company_title_matrix.sort_values('total', ascending=False).drop('total', axis=1)

# Plot the bar chart
company_title_matrix.plot(kind='bar', stacked=True, figsize=(12,6))
plt.title('Job Title Distribution for Top 20 Companies')
plt.xlabel('Job Titles')
plt.ylabel('Counts')
plt.legend(title='Companies', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Concatenate all job titles into a single string
job_titles = ' '.join(df['job_title'].astype(str))

# Generate a word cloud
wordcloud = WordCloud(width=800, height=400, background_color='black', colormap='Spectral_r', max_words=50).generate(job_titles)

# Plot the word cloud
plt.figure(figsize=(10,6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Convert job titles to string and join them
job_titles = ' '.join(df['job_title'].dropna().astype(str))

# Create a word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(job_titles)

# Plot the word cloud
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of Job Titles')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS
import numpy as np
from PIL import Image

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Convert job titles to string and join them
job_titles = ' '.join(df['job_title'].dropna().astype(str))

# Load a circle mask
circle_mask = np.array(Image.open("image.png"))

# Create a word cloud with circle mask
wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=STOPWORDS, mask=circle_mask).generate(job_titles)

# Plot the word cloud
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of Job Titles')
plt.show()

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Create a new dataframe to hold job title counts for each company
job_counts = df.groupby(['company_name', 'job_title'])['job_title'].count().unstack().fillna(0)

# Compute correlation matrix
corr_matrix = job_counts.corr()

# Replace diagonal values with NaN
np.fill_diagonal(corr_matrix.values, np.nan)

# Plot correlation matrix
plt.figure(figsize=(10, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)
plt.title('Correlation Matrix of Job Title Counts')
plt.show()

import pandas as pd
from datetime import datetime

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')


# Convert the date column to datetime format
df['date'] = pd.to_datetime(df['date'])

# Extract the month from the date column and create a new column for it
df['month'] = df['date'].apply(lambda x: datetime.strftime(x, '%B') if not pd.isnull(x) else '')

# Print the first few rows of the updated dataset
print(df.head())

import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')


# Convert the date column to datetime format
df['date'] = pd.to_datetime(df['date'])

# Extract the month from the date column and create a new column for it
df['month'] = df['date'].apply(lambda x: datetime.strftime(x, '%B') if not pd.isnull(x) else '')

# Get the top 10 job titles by count
top_job_titles = df['job_title'].value_counts().nlargest(10).index.tolist()

# Filter the data to only include the top 10 job titles
df_top_jobs = df[df['job_title'].isin(top_job_titles)]

# Group the data by job title and month and count the number of occurrences
title_month_counts = df_top_jobs.groupby(['job_title', 'month']).size().reset_index(name='counts')

# Pivot the data to create a matrix with job titles as rows and months as columns
title_month_matrix = title_month_counts.pivot(index='job_title', columns='month', values='counts').fillna(0)

# Plot a heatmap of the matrix
plt.figure(figsize=(10,10))
plt.imshow(title_month_matrix, cmap='Reds')
plt.xticks(range(len(title_month_matrix.columns)), title_month_matrix.columns, rotation=90)
plt.yticks(range(len(title_month_matrix.index)), title_month_matrix.index)
plt.xlabel('Month')
plt.ylabel('Job Title')
plt.colorbar()
plt.show()

import pandas as pd

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Group the data by company and job title and count the number of occurrences
company_title_counts = df.groupby(['company_name', 'job_title']).size().reset_index(name='counts')

# Sort the data by company and counts in descending order
company_title_counts = company_title_counts.sort_values(['company_name', 'counts'], ascending=[True, False])

# Add a rank column based on the counts for each company
company_title_counts['rank'] = company_title_counts.groupby('company_name')['counts'].rank(ascending=False)

# Print the top 10 job titles for each company
for company in company_title_counts['company_name'].unique():
    print(f"Top 10 job titles for {company}:")
    company_jobs = company_title_counts[company_title_counts['company_name'] == company].head(10)
    for i, row in company_jobs.iterrows():
        print(f"{row['rank']}. {row['job_title']} ({row['counts']} job postings)")
    print('\n')

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Compute the count of job titles by seniority level
counts = df.groupby(['seniority_level', 'job_title']).size().reset_index(name='count')

# Compute the rank of job titles by seniority level
counts['rank'] = counts.groupby('seniority_level')['count'].rank(method='dense', ascending=False)

# Keep only the top 10 job titles by count
top_10_counts = counts[counts['rank'] <= 10]

# Pivot the data to create a matrix with seniority levels as rows and job titles as columns
pivot = top_10_counts.pivot(index='seniority_level', columns='job_title', values='count').fillna(0)

# Plot the data as a horizontal bar chart
fig, ax = plt.subplots(figsize=(12, 8))
pivot.plot.barh(ax=ax)
ax.set_xlabel('Count')
ax.set_ylabel('Seniority Level')
ax.set_title('Top 10 Job Titles by Seniority Level')
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Compute the count of job titles by seniority level
counts = df.groupby(['seniority_level', 'job_title']).size().reset_index(name='count')

# Compute the rank of job titles by seniority level
counts['rank'] = counts.groupby('seniority_level')['count'].rank(method='dense', ascending=False)

# Keep a random sample of job titles
n_sample = 15
sample_titles = np.random.choice(counts['job_title'].unique(), size=n_sample, replace=False)
top_sample_counts = counts[counts['job_title'].isin(sample_titles)]

# Pivot the data to create a matrix with seniority levels as rows and job titles as columns
pivot = top_sample_counts.pivot(index='seniority_level', columns='job_title', values='count').fillna(0)

# Plot the data as a horizontal bar chart
fig, ax = plt.subplots(figsize=(12, 8))
pivot.plot.barh(ax=ax)
ax.set_xlabel('Count')
ax.set_ylabel('Seniority Level')
ax.set_title(f'Top {n_sample} Job Titles by Seniority Level (Random Sample)')
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Select a sample of job titles
job_titles = ['Data Scientist', 'Software Engineer', 'Product Manager', 'Marketing Manager', 'Sales Representative']

# Filter the dataset to keep only the selected job titles
df_sample = df[df['job_title'].isin(job_titles)]

# Compute the count of job titles by seniority level
counts = df_sample.groupby(['seniority_level', 'job_title']).size().reset_index(name='count')

# Compute the rank of job titles by seniority level
counts['rank'] = counts.groupby('seniority_level')['count'].rank(method='dense', ascending=False)

# Pivot the data to create a matrix with seniority levels as rows and job titles as columns
pivot = counts.pivot(index='seniority_level', columns='job_title', values='count').fillna(0)

# Create a heatmap of the data
fig, ax = plt.subplots(figsize=(8, 6))
im = ax.imshow(pivot, cmap='Blues')

# Add annotations of the counts
for i in range(len(job_titles)):
    for j in range(len(pivot.index)):
        text = ax.text(i, j, int(pivot.iloc[j, i]), ha='center', va='center', color='w')

# Add labels and title
ax.set_xticks(np.arange(len(job_titles)))
ax.set_yticks(np.arange(len(pivot.index)))
ax.set_xticklabels(job_titles)
ax.set_yticklabels(pivot.index)
ax.set_xlabel('Job Title')
ax.set_ylabel('Seniority Level')
ax.set_title('Ranking of a Sample of Job Titles by Seniority Level')

# Rotate the x-axis labels
plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')

# Add a colorbar
cbar = ax.figure.colorbar(im, ax=ax)
cbar.ax.set_ylabel('Count', rotation=-90, va='bottom')

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Compute the top 10 job titles by count
job_counts = df['job_title'].value_counts().nlargest(10).index.tolist()

# Filter the dataset to keep only the top 10 job titles
df_top10 = df[df['job_title'].isin(job_counts)]

# Compute the count of job titles by seniority level
counts = df_top10.groupby(['seniority_level', 'job_title']).size().reset_index(name='count')

# Compute the rank of job titles by seniority level
counts['rank'] = counts.groupby('seniority_level')['count'].rank(method='dense', ascending=False)

# Pivot the data to create a matrix with seniority levels as rows and job titles as columns
pivot = counts.pivot(index='seniority_level', columns='job_title', values='count').fillna(0)

# Create a heatmap of the data
fig, ax = plt.subplots(figsize=(8, 6))
im = ax.imshow(pivot, cmap='Blues')

# Add annotations of the counts
for i in range(len(job_counts)):
    for j in range(len(pivot.index)):
        text = ax.text(i, j, int(pivot.iloc[j, i]), ha='center', va='center', color='w')

# Add labels and title
ax.set_xticks(np.arange(len(job_counts)))
ax.set_yticks(np.arange(len(pivot.index)))
ax.set_xticklabels(job_counts)
ax.set_yticklabels(pivot.index)
ax.set_xlabel('Job Title')
ax.set_ylabel('Seniority Level')
ax.set_title('Ranking of Top 10 Job Titles by Seniority Level')

# Rotate the x-axis labels
plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')

# Add a colorbar
cbar = ax.figure.colorbar(im, ax=ax)
cbar.ax.set_ylabel('Count', rotation=-90, va='bottom')

plt.tight_layout()
plt.show()

import pandas as pd

# Load dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Group by industry and job_title and count the number of occurrences
industry_job_counts = df.groupby(['industry', 'job_title']).size().reset_index(name='count')

# Sort by count in descending order
industry_job_counts = industry_job_counts.sort_values(by=['count'], ascending=False)

# Print top 10 industries with highest job postings
top_10_industries = industry_job_counts['industry'].value_counts().nlargest(50)
print('Top 50 industries with highest job postings:')
print(top_10_industries)

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')
# Convert 'date' column to datetime format
df['date'] = pd.to_datetime(df['date'])

# Extract year from 'date' column
df['year'] = df['date'].dt.year


# Create a new dataframe grouped by industry and year
df_by_industry_year = df.groupby(['industry', 'year'])['job_title'].count().reset_index()

# Pivot the dataframe to create columns for each industry
df_pivot = df_by_industry_year.pivot(index='year', columns='industry', values='job_title')

# Plot the line chart
ax = df_pivot.plot(kind='line', figsize=(12,8), lw=3)
ax.set_xlabel('Year', fontsize=16)
ax.set_ylabel('Number of Job Postings', fontsize=16)
ax.set_title('Job Postings by Industry over Time', fontsize=20)
plt.legend(fontsize=6)
plt.legend(loc='center left', bbox_to_anchor=(1.05, 0.5))
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Extract year from date attribute
df['year'] = pd.DatetimeIndex(df['date']).year

# Select top 20 industries by number of job postings
top_20_industries = df['industry'].value_counts().head(20).index.tolist()

# Filter the dataframe to only include job postings from the top 20 industries
df_top_20 = df[df['industry'].isin(top_20_industries)]

# Group by industry and year to get the count of job postings
industry_year_counts = df_top_20.groupby(['industry', 'year']).size().reset_index(name='count')

# Pivot the dataframe to get the count of job postings by year for each industry
pivot_df = industry_year_counts.pivot(index='year', columns='industry', values='count')

# Plot the line chart
plt.figure(figsize=(8, 8))
sns.set_palette('husl', n_colors=20)
sns.lineplot(data=pivot_df, linewidth=2.5)
plt.title('Trend of Job Postings by Industry (Top 20)')
plt.xlabel('Year')
plt.ylabel('Number of Job Postings')
plt.legend(loc='center left', bbox_to_anchor=(1.05, 0.5))
plt.show()

top_20_industries = df['industry'].value_counts().head(20).index.tolist()

# Filter the dataframe to only include job postings from the top 20 industries
df_top_20 = df[df['industry'].isin(top_20_industries)]

# Group by industry and year to get the count of job postings
industry_year_counts = df_top_20.groupby(['industry', 'year']).size().reset_index(name='count')

# Pivot the dataframe to get the count of job postings by year for each industry
df_pivot = industry_year_counts.pivot(index='year', columns='industry', values='count')

# Plot the line chart
ax = df_pivot.plot(kind='line', figsize=(12,8), lw=3)
ax.set_xlabel('Year', fontsize=16)
ax.set_ylabel('Number of Job Postings', fontsize=16)
ax.set_title('Job Postings by Industry over Time', fontsize=20)
plt.legend(fontsize=6)
plt.legend(loc='center left', bbox_to_anchor=(1.05, 0.5))
plt.show()

import numpy as np
# Get the top 20 industries by count
top_industries = df.groupby('industry').size().sort_values(ascending=False)[:20].index.tolist()

# Filter the dataframe to include only the top 20 industries
df_top20 = df[df['industry'].isin(top_industries)]

# Pivot the dataframe to get job titles count by industry
pivot_df = industry_year_counts.pivot(index='year', columns='industry', values='count')
#pivot_df = df_top20.pivot_table(index='industry', columns='job_title', values='count', aggfunc=np.sum, fill_value=0)

# Create a stacked bar chart
pivot_df.plot(kind='bar', stacked=True, figsize=(15, 8))

# Set chart title and axes labels
plt.title('Job Title Distribution by Industry (Top 20 Industries)')
plt.xlabel('Industry')
plt.ylabel('Job Title Count')

# Show the legend outside the plot
plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))

# Show the plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Group the data by industry and job title, and count the number of job postings
grouped_df = df.groupby(['industry', 'job_title']).size().reset_index(name='count')

# Pivot the dataframe to get job titles count by industry
pivot_df = grouped_df.pivot(index='industry', columns='job_title', values='count').fillna(0)

# Create a stacked bar chart
pivot_df.plot(kind='bar', stacked=True, figsize=(12,8))

# Add title and labels
plt.title('Distribution of Job Titles Across Industries')
plt.xlabel('Industry')
plt.ylabel('Number of Job Postings')

# Show the plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel("/content/cleaned_linkedin_job_posts.xlsx")

# Get the top 50 job titles by count
top50_jobs = df['job_title'].value_counts().nlargest(20)

# Filter the dataset to include only the top 50 job titles
df_top50 = df[df['job_title'].isin(top50_jobs.index)]

# Create a pivot table of job counts by industry and job title
pivot_table = pd.pivot_table(df_top50, values='date', index='industry', columns='job_title', aggfunc='size', fill_value=0)

# Sort industries by total job count
pivot_table['Total'] = pivot_table.sum(axis=1)
pivot_table = pivot_table.sort_values(by='Total', ascending=False).drop('Total', axis=1)

# Plot the stacked bar chart
ax = pivot_table.plot(kind='bar', stacked=True, figsize=(16,8))
ax.set_xlabel('Industry')
ax.set_ylabel('Job Count')
plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')
ax.set_title('Distribution of Job Titles Across Different Industries (Top 50)')
ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_excel("/content/cleaned_linkedin_job_posts.xlsx")

# Get the top 20 industries by job count
top20_industries = df['industry'].value_counts().nlargest(30).index.tolist()

# Filter the dataset to include only the top 20 industries
df_top20 = df[df['industry'].isin(top20_industries)]

# Get a sample of 50 job titles
sample_job_titles = df['job_title'].value_counts().nlargest(50).index.tolist()

# Filter the dataset to include only the sample of 50 job titles
df_sample50 = df[df['job_title'].isin(sample_job_titles)]

# Create a pivot table of job counts by industry and job title
pivot_table = pd.pivot_table(df_sample50, values='date', index='industry', columns='job_title', aggfunc='size', fill_value=0)

# Sort industries by total job count
industry_counts = df_top20['industry'].value_counts().sort_values(ascending=False).index

# Create a stacked bar chart
pivot_table.loc[industry_counts].plot(kind='bar', stacked=True, figsize=(13,10))

# Set chart properties
plt.title('Distribution of Job Titles Across Top 20 Industries')
plt.xlabel('Industry')
plt.ylabel('Number of Job Postings')
plt.legend(loc='center left', bbox_to_anchor=(1.0,0.32))

plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the data
#df = pd.read_csv('jobs.csv')

# Get the top 20 industries by job count
top20_industries = df['industry'].value_counts().nlargest(20).index.tolist()

# Get a sample of 50 job titles
sample_job_titles = df['job_title'].unique()[:10]

# Filter the data to only include the top 20 industries and the sample of 50 job titles
df_filtered = df[df['industry'].isin(top20_industries) & df['job_title'].isin(sample_job_titles)]

# Group the data by industry and job title and get the count
df_grouped = df_filtered.groupby(['industry', 'job_title']).size().reset_index(name='count')

# Normalize the count values to use as bubble sizes
df_grouped['count_normalized'] = df_grouped['count'] / df_grouped['count'].max()

# Plot the bubble chart
plt.figure(figsize=(12,8))
sns.scatterplot(data=df_grouped, x='job_title', y='industry', size='count_normalized', sizes=(50, 1000), alpha=0.8)
plt.title('Distribution of Job Titles Across Industries', fontsize=16)
plt.xlabel('Job Title', fontsize=12)
plt.ylabel('Industry', fontsize=12)
plt.show()

!pip install squarify
df=pd.read_excel("/content/cleaned_linkedin_job_posts.xlsx")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import squarify

# Read in the job listings data
#df = pd.read_csv('job_listings.csv')

# Filter out any job listings with missing industry or job title
df = df.dropna(subset=['industry', 'job_title'])

# Get the top 20 industries by job count
industry_counts = df['industry'].value_counts().nlargest(20)
top20_industries = industry_counts.index.tolist()

# Filter the data to only include the top 20 industries
df_top20 = df[df['industry'].isin(top20_industries)]

# Create a pivot table of job counts by industry and job title
pivot_table = pd.pivot_table(df_top20, values='date', index='industry', columns='job_title', aggfunc='count', fill_value=0)

# Compute the total number of jobs by industry
industry_totals = df_top20.groupby('industry')['date'].count()

# Compute the total number of jobs by job title
job_totals = df_top20.groupby('job_title')['date'].count()

# Define a function to create a tree map for a given industry
def create_treemap(industry):
    # Filter the pivot table to only include the specified industry
    data = pivot_table.loc[[industry]]

    # Calculate the relative job count for each job title
    rel_job_counts = data.div(industry_totals[industry], axis=1).iloc[0]

    # Sort the job titles by their relative job count
    rel_job_counts = rel_job_counts.sort_values(ascending=False)

    # Get the color map
    cmap = plt.get_cmap('Blues')

    # Create a list of colors for the rectangles
    colors = [cmap(x) for x in np.linspace(0, 1, len(rel_job_counts))]

    # Create the tree map rectangles
    rects = squarify.squarify(rel_job_counts, pad=True, color=colors, alpha=0.8)

    # Add labels for each rectangle
    labels = [f"{title}\n({count:,} jobs)" for title, count in zip(rel_job_counts.index, data.loc[industry])]

    # Create a list of font sizes for the labels
    font_sizes = [8 + (i // 10) for i in range(len(rel_job_counts))]

    # Create the tree map figure
    plt.figure(figsize=(8, 6))
    plt.title(industry)
    plt.axis('off')
    squarify.plot(sizes=rel_job_counts, label=labels, alpha=0.8, pad=True, color=colors, text_kwargs={'fontsize': font_sizes})
    plt.show()

# Create a tree map for each industry in the top 20
for industry in top20_industries:
    create_treemap(industry)

import pandas as pd
import matplotlib.pyplot as plt
import squarify

# Load the data
#df = pd.read_csv('jobs.csv')

# Select the top 20 industries by job count
top20_industries = df['industry'].value_counts().nlargest(30).index.tolist()
df_top20 = df[df['industry'].isin(top20_industries)]

# Convert 'date' column to numeric data type
df_top20['date'] = pd.to_numeric(df_top20['date'], errors='coerce')

# Create a pivot table of job counts by industry and job title
pivot_table = pd.pivot_table(df_top20, values='date', index='industry', columns='job_title', aggfunc='sum', fill_value=0)

# Compute the total number of jobs by industry
total_jobs = pivot_table.sum(axis=1)

# Compute the percentage of jobs by industry
pct_jobs = total_jobs / total_jobs.sum()

# Create a treemap
plt.figure(figsize=(10,10))
squarify.plot(sizes=pct_jobs, label=top20_industries, alpha=.8)
plt.axis('off')
plt.title('Job Distribution by Industry')
plt.show()

import squarify
import matplotlib.pyplot as plt

# Create a pivot table of job counts by industry and job title
pivot_table = pd.pivot_table(df_top20, values='date', index='industry', columns='job_title', aggfunc='count', fill_value=0)

# Compute the total number of jobs by industry
job_counts = df_top20.groupby('industry').size().sort_values(ascending=False)

# Define the color map
cmap = plt.cm.get_cmap('Paired')

# Define the plot parameters
fig, ax = plt.subplots(figsize=(12, 8))
squarify.plot(sizes=job_counts.values, label=job_counts.index, color=[cmap(i) for i in range(len(job_counts))], alpha=.8)

# Configure the plot
plt.axis('off')
plt.title('Job Title Distribution by Industry (Top 20)', fontsize=16, fontweight='bold')
plt.show()

import numpy as np

# Extract year from date attribute
df['year'] = pd.DatetimeIndex(df['date']).year
# Get the top 20 industries by count
top_industries = df.groupby('industry').size().sort_values(ascending=False)[:20].index.tolist()

# Filter the dataframe to include only the top 20 industries
df_top20 = df[df['industry'].isin(top_industries)]

# Pivot the dataframe to get job titles count by industry and year
pivot_df = pd.pivot_table(df_top20, values='date', index='year', columns='industry', aggfunc='count', fill_value=0)

# Create a stacked bar chart
pivot_df.plot(kind='barh', stacked=True, figsize=(15, 8))

# Set chart title and axes labels
plt.title('Job Title Distribution by Industry and Year (Top 20 Industries)')
plt.xlabel('Job Title Count')
plt.ylabel('Year')
plt.xlim(0,4000)
# Show the legend outside the plot
plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))

# Show the plot
plt.show()

import seaborn as sns

# Get the top 20 industries by count
top_industries = df.groupby('industry').size().sort_values(ascending=False)[:20].index.tolist()

# Filter the dataframe to include only the top 20 industries
df_top20 = df[df['industry'].isin(top_industries)]

# Filter the dataframe to include only the year 2023
#df_2023 = df_top20[df_top20['year']==2023]

# Pivot the dataframe to get job titles count by industry
pivot_df = pd.pivot_table(df_top20, values='date', index='year', columns='industry', aggfunc='count', fill_value=0)
#pivot_table = pd.pivot_table(df_top20, values='count', index='industry', columns='job_title', aggfunc=np.sum, fill_value=0)

# Create a heatmap
fig, ax = plt.subplots(figsize=(12, 6))
sns.heatmap(pivot_df, cmap="inferno", annot=True, fmt="d", linewidths=.5, ax=ax)

#sns.heatmap(pivot_df, cmap='YlGnBu', annot=True, fmt='d')

# Set chart title and axes labels
plt.title('Job Title Distribution by Industry for Year')
plt.xlabel('Job Title')
plt.ylabel('Industry')

# Show the plot
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt


# Load the dataset
df = pd.read_excel('/content/cleaned_linkedin_job_posts.xlsx')

# Extract month information from date attribute
df['month'] = pd.DatetimeIndex(df['date']).month

# Select a sample of job titles
job_titles = df['job_title'].value_counts().nlargest(10).index.tolist()
df = df[df['job_title'].isin(job_titles)]

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df[['company_name', 'location', 'employment_type', 'month']], df['job_title'], test_size=0.2, random_state=42)

# Vectorize the textual features using TF-IDF
vectorizer = TfidfVectorizer()
X_train_text = vectorizer.fit_transform(X_train[['company_name', 'location', 'employment_type']].apply(lambda x: ' '.join(str(i) for i in x), axis=1))
X_test_text = vectorizer.transform(X_test[['company_name', 'location', 'employment_type']].apply(lambda x: ' '.join(str(i) for i in x), axis=1))

# Combine the vectorized features with the month feature
import scipy.sparse as sp
X_train_final = sp.hstack([X_train_text, X_train[['month']]])
X_test_final = sp.hstack([X_test_text, X_test[['month']]])

# Train a Naive Bayes classifier
clf = MultinomialNB()
clf.fit(X_train_final, y_train)

# Make predictions on the testing set
y_pred = clf.predict(X_test_final)
cm= confusion_matrix(y_test, y_pred)
# Evaluate the performance of the classifier
print('Accuracy:', accuracy_score(y_test, y_pred))
sns.heatmap(cm,annot=True,fmt='g')
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()

from sklearn.ensemble import RandomForestClassifier

# Initialize the model
rf = RandomForestClassifier()

# Fit the model on the training data
rf.fit(X_train_text, y_train)

# Predict job titles for test data
y_pred_rf = rf.predict(X_test_text)

# Evaluate model performance
print("Accuracy:", accuracy_score(y_test, y_pred_rf))

from sklearn.tree import DecisionTreeClassifier

# Initialize the model
dt = DecisionTreeClassifier()

# Fit the model on the training data
dt.fit(X_train_text, y_train)

# Predict job titles for test data
y_pred_dt = dt.predict(X_test_text)

# Evaluate model performance
print("Accuracy:", accuracy_score(y_test, y_pred_dt))

from sklearn.svm import SVC

# Initialize the model
svm = SVC()

# Fit the model on the training data
svm.fit(X_train_text, y_train)

# Predict job titles for test data
y_pred_svm = svm.predict(X_test_text)

# Evaluate model performance
print("Accuracy:", accuracy_score(y_test, y_pred_svm))

# Generate confusion matrix
cm_svm = confusion_matrix(y_test, y_pred_svm)

# Visualize confusion matrix
sns.heatmap(cm_svm, annot=True, fmt="d")
plt.title("SVM Confusion Matrix")
plt.show()

from sklearn.metrics import confusion_matrix
from sklearn import svm
from sklearn.metrics import classification_report

# Train SVM model
svm_model = svm.SVC(kernel='linear')
svm_model.fit(X_train_text, y_train)

# Evaluate model performance on test data
y_pred_svm = svm_model.predict(X_test_text)
print(classification_report(y_test, y_pred_svm))

# Generate confusion matrix
cm_svm = confusion_matrix(y_test, y_pred_svm)
# Evaluate model performance
print("Accuracy:", accuracy_score(y_test, y_pred_svm))

# Visualize confusion matrix
sns.heatmap(cm_svm, annot=True, fmt="d")
plt.title("SVM Confusion Matrix")
plt.show()

from sklearn.ensemble import GradientBoostingClassifier

# Initialize the model
gb = GradientBoostingClassifier()

# Fit the model on the training data
gb.fit(X_train_text, y_train)

# Predict job titles for test data
y_pred_gb = gb.predict(X_test_text)

# Evaluate model performance
print("Accuracy:", accuracy_score(y_test, y_pred_gb))

import pandas as pd

# load the data into a pandas DataFrame
#df = pd.read_csv('your_file_path.csv')

# group the data by job_title and company_name and count the occurrences of each job_title within each company
job_title_counts = df.groupby(['job_title', 'company_name']).size().reset_index(name='count')

# sort the resulting DataFrame in descending order based on the count of job_title occurrences
sorted_counts = job_title_counts.sort_values(by='count', ascending=False)

# select the top 10 job titles based on the count of occurrences within all companies
top_10_job_titles = sorted_counts['job_title'].value_counts().head(100)

# print the resulting DataFrame
print(top_10_job_titles)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# group the data by job_title and company_name and count the occurrences of each job_title within each company
job_title_counts = df.groupby(['job_title', 'company_name']).size().reset_index(name='count')

# sort the resulting DataFrame in descending order based on the count of job_title occurrences
sorted_counts = job_title_counts.sort_values(by='count', ascending=False)

# select the top 10 job titles based on the count of occurrences within all companies
top_10_job_titles = sorted_counts['job_title'].value_counts().head(10).index.tolist()

# pivot the DataFrame so that the columns are the job titles and the rows are the company names, with the counts as the values
pivoted_counts = sorted_counts[sorted_counts['job_title'].isin(top_10_job_titles)].pivot(index='company_name', columns='job_title', values='count').fillna(0)

# create a heatmap of the pivoted DataFrame using Seaborn
sns.heatmap(pivoted_counts, cmap="YlGnBu")

# set the plot title
plt.title('Top 10 Job Titles Posted by Companies')

# display the plot
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# group the data by job_title and company_name and count the occurrences of each job_title within each company
job_title_counts = df.groupby(['job_title', 'company_name']).size().reset_index(name='count')

# create a pivot table with the job_title as the index, the company_name as the columns, and the count of job_title occurrences as the values
job_title_pivot = pd.pivot_table(job_title_counts, values='count', index='job_title', columns='company_name', aggfunc=sum)

# select the top 10 job titles based on the count of occurrences within all companies
top_10_job_titles = job_title_counts['job_title'].value_counts().head(10).index.tolist()

# filter the pivot table to only include the top 10 job titles
job_title_pivot = job_title_pivot.loc[top_10_job_titles]

# plot the resulting pivot table as a heatmap using the seaborn library
sns.heatmap(job_title_pivot, cmap='YlGnBu')

# set the plot title and labels
plt.title('Top 10 Job Titles Posted by Companies')
plt.xlabel('Company Name')
plt.ylabel('Job Title')

# show the plot
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# load the data into a pandas DataFrame
#df = pd.read_csv('your_file_path.csv')

# group the data by job_title and company_name and count the occurrences of each job_title within each company
job_title_counts = df.groupby(['job_title', 'company_name']).size().reset_index(name='count')

# create a pivot table with the job_title as the index, the company_name as the columns, and the count of job_title occurrences as the values
job_title_pivot = pd.pivot_table(job_title_counts, values='count', index='job_title', columns='company_name', aggfunc=sum, fill_value=0)

# select the top 10 company names based on the count of job title occurrences within all companies
top_10_companies = job_title_counts.groupby('company_name')['count'].sum().nlargest(10).index.tolist()

# filter the pivot table to only include the top 10 company names
job_title_pivot = job_title_pivot[top_10_companies]

# select the top 10 job titles for each of the top 10 companies based on the count of job title occurrences
top_10_job_titles = []
for company in top_10_companies:
    top_10_job_titles.extend(job_title_counts[job_title_counts['company_name'] == company].nlargest(1, 'count')['job_title'].tolist())

# filter the pivot table to only include the top 10 job titles for each of the top 10 companies
job_title_pivot = job_title_pivot.loc[top_10_job_titles]

# plot the resulting pivot table as a heatmap using the seaborn library
sns.heatmap(job_title_pivot, cmap='rocket',annot=True,fmt='d')

# set the plot title and labels
plt.title('Top 10 Job Titles Posted by Top 10 Companies')
plt.xlabel('Company Name')
plt.ylabel('Job Title')
plt.figure(figsize=(10,10))

# show the plot
plt.show()

